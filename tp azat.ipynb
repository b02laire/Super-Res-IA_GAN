{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "from tensorflow.keras import layers,Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (60000, 28, 28, 1)\n",
      "Test set shape: (10000, 28, 28, 1)\n",
      "Train categorical labels shape: (60000, 10)\n",
      "Test categorical labels shape: (10000, 10)\n",
      "2 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4c7ce03f28>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train= x_train/127.5 -1\n",
    "y_train= y_train/127.5 -1\n",
    "# Add one dimmention for the grayscale channel\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# Labels to categorical (one hot)\n",
    "y_train_cat = to_categorical(y_train, num_classes=10)\n",
    "y_test_cat = to_categorical(y_test, num_classes=10)\n",
    "# Display dataset info\n",
    "print ('Train set shape:', x_train.shape)\n",
    "print ('Test set shape:', x_test.shape)\n",
    "print ('Train categorical labels shape:', y_train_cat.shape)\n",
    "print ('Test categorical labels shape:', y_test_cat.shape)\n",
    "# Show one example\n",
    "2\n",
    "print (y_test[1], y_test_cat[1])\n",
    "plt.imshow(x_test[9999,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                10250     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 818,186\n",
      "Trainable params: 816,138\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "60000/60000 [==============================] - 13s 211us/sample - loss: 0.0597 - accuracy: 0.9864 - val_loss: 1124.2605 - val_accuracy: 0.0028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4b502f6780>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Discriminator using DNN\n",
    "D = Sequential(name='Discriminator')\n",
    "# Layer 1\n",
    "D.add(Flatten(input_shape=(28, 28, 1)))\n",
    "D.add(Dense(1024))\n",
    "3\n",
    "D.add(BatchNormalization())\n",
    "D.add(Activation('relu'))\n",
    "# Layer 2\n",
    "D.add(Dense(10))\n",
    "D.add(Activation('softmax'))\n",
    "D.compile(loss='categorical_crossentropy', optimizer=Adam(0.0001, 0.5), metrics=['accuracy'])\n",
    "D.summary()\n",
    "D.fit(x_train, y_train_cat, validation_data=(x_test, y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 14, 14, 32)        832       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 7, 7, 64)          51264     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 520,586\n",
      "Trainable params: 520,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "60000/60000 [==============================] - 17s 276us/sample - loss: 0.0473 - accuracy: 0.9877 - val_loss: 1110.7314 - val_accuracy: 0.0040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4b286ddcf8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Discriminator using CNN\n",
    "D = Sequential(name='Discriminator')\n",
    "# Layer 1\n",
    "D.add(Conv2D(32, (5, 5), strides=(2, 2), padding='same', input_shape=(28, 28, 1)))\n",
    "D.add(Activation('relu'))\n",
    "# Layer 2\n",
    "D.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same'))\n",
    "D.add(Activation('relu'))\n",
    "# Layer 3\n",
    "D.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "D.add(Activation('relu'))\n",
    "# Layer 4\n",
    "D.add(Flatten())\n",
    "D.add(Dense(128))\n",
    "D.add(Activation('relu'))\n",
    "# Layer 5\n",
    "D.add(Dense(10))\n",
    "D.add(Activation('softmax'))\n",
    "D.compile(loss='categorical_crossentropy', optimizer=Adam(0.0001, 0.5), metrics=['accuracy'])\n",
    "D.summary()\n",
    "D.fit(x_train, y_train_cat, validation_data=(x_test, y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_noise=100 #taille du vecteur de bruit gaussien\n",
    "\n",
    "G= Sequential()\n",
    "G.add(Dense(256,input_shape=(100,) ))\n",
    "G.add(BatchNormalization() )\n",
    "G.add(Activation('relu'))\n",
    "#add more layers here\n",
    "G.add(Reshape((28,28,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (None, 28, 28, 1)         26880     \n",
      "_________________________________________________________________\n",
      "Discriminator (Sequential)   (None, 10)                520586    \n",
      "=================================================================\n",
      "Total params: 547,466\n",
      "Trainable params: 26,368\n",
      "Non-trainable params: 521,098\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "D.compile(loss='binary_crossentropy', optimizer=Adam(0.0001, 0.5))\n",
    "D.trainable = False\n",
    "gan_input = Input(shape=(100,))\n",
    "gan_output = D(G(gan_input))\n",
    "gan = Model(gan_input, gan_output) # This is the combined model\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam(0.0001, 0.5))\n",
    "gan.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "x_train_c = x_train[np.where(y_train == 4)[0]] # Lets train only for numbers 4\n",
    "num_batches = int(len(x_train_c) / batch_size)\n",
    "for epoch in range(20):\n",
    "    for batch in range(num_batches):\n",
    "        # Select a random batch from x_train_c\n",
    "        x = x_train_c[np.random.randint(0, len(x_train_c), size=batch_size)]\n",
    "        # Gaussian noise for the generator model\n",
    "        noise = np.random.normal(0, 1, size=[batch_size, 100])\n",
    "        # Generate fake images\n",
    "        gen_imgs = G.predict(noise)\n",
    "        disc_data = np.concatenate([x, gen_imgs])\n",
    "        # True images are labeled 1, false ones are 0\n",
    "        labels = [0.9]*batch_size + [0]*batch_size\n",
    "        D.trainable = True\n",
    "        dloss = D.train_on_batch(disc_data, labels)\n",
    "        D.trainable = False # Freeze the discriminator\n",
    "        gloss = gan.train_on_batch(noise, [1]*batch_size)\n",
    "        print ('\\b'*79 + '\\r', end='')\n",
    "        print ('Epoch %d, batch %d/%d: ' % (epoch+1, batch, num_batches) + ' gloss=%.4f, dloss=%.4f' % (gloss, dloss), end='')\n",
    "    print ('')\n",
    "# Save the weights after training\n",
    "G.save_weights('./gen_weights.hdf5')\n",
    "D.save_weights('./disc_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.31980929e+00  8.00345540e-01  5.64266276e-01  2.18865689e-01\n",
      "   1.55962424e+00  8.65688831e-01 -2.98139455e+00  1.07058608e+00\n",
      "  -4.59096046e-01 -1.51853120e+00 -1.99593912e+00 -1.01738144e+00\n",
      "  -2.90465650e-01  5.62735510e-01 -4.97763398e-02  1.44678660e-01\n",
      "  -1.49704183e+00  1.50826992e-01  3.66634515e-02 -1.14769511e-01\n",
      "   8.67776923e-01  1.92358142e-01 -1.35606102e+00 -2.16261296e+00\n",
      "  -2.93073016e-01 -2.04520110e+00 -1.85520613e+00  4.81096568e-01\n",
      "  -4.87085964e-01 -5.57275748e-01  2.72589399e+00  4.54678133e-01\n",
      "  -1.82683235e+00  5.44526607e-01 -2.29443245e+00  4.36131302e-01\n",
      "   2.18105331e-01 -7.07051063e-01  1.69667296e+00 -9.69078949e-02\n",
      "  -1.09780104e+00  5.62098114e-01  2.50288166e-01  7.19797707e-01\n",
      "  -4.77100954e-01  1.83668581e+00  8.28656959e-01 -1.28767152e+00\n",
      "   4.20910415e-01  5.46724043e-01 -1.26519000e+00 -5.26115161e-01\n",
      "   4.10045218e-01  1.50093354e+00  7.78848675e-01 -1.67713508e+00\n",
      "  -6.07898243e-01 -3.89366508e-01 -1.07379924e+00  2.98014745e-01\n",
      "  -1.31930347e+00 -2.79282959e-01  4.62810961e-01  1.89586928e+00\n",
      "  -1.66382835e+00  5.22137397e-01 -1.50041044e+00 -8.60597217e-05\n",
      "   1.05012033e-01 -3.19823622e-01 -1.99154243e+00  8.28627050e-01\n",
      "   1.60882791e-01  2.14579320e-01 -8.66858679e-01 -4.33025720e-01\n",
      "   4.49975412e-02 -6.14631304e-01 -1.16554591e+00 -8.19697195e-01\n",
      "  -1.62429298e+00  5.86505072e-02  1.09033778e+00 -4.06418445e-01\n",
      "   7.46268055e-01  4.99629972e-02 -1.02424360e+00  3.40946283e-01\n",
      "   8.76215345e-01 -7.81271697e-01 -2.66418888e-01  1.19925548e+00\n",
      "  -3.40610242e+00 -3.92281122e-01  6.40372031e-01  1.75839139e+00\n",
      "   9.27007942e-01 -1.42544583e+00  5.80158292e-01 -4.15338506e-01]\n",
      " [-2.75527331e-01 -1.67238166e+00  1.43130441e+00 -1.38566041e-01\n",
      "   8.14220346e-01  2.66178699e+00 -6.21598960e-01 -1.40155031e+00\n",
      "   1.18951801e+00 -1.48485855e+00 -9.45965149e-01 -1.43871267e+00\n",
      "  -5.27528543e-01  2.10638863e+00 -1.19225657e+00  1.21905577e+00\n",
      "   1.84078296e-01 -1.90712363e+00 -1.51435797e-01 -7.16256981e-02\n",
      "  -1.37309155e+00 -7.15200089e-01  1.82618121e+00  4.36184198e-01\n",
      "  -7.49975134e-01 -7.58131432e-01  7.27190568e-01  1.00192076e+00\n",
      "   9.53098488e-01  8.05472147e-01 -1.40632432e+00  1.39576301e+00\n",
      "   4.37965013e-01 -1.41557874e+00 -1.27989626e+00 -3.05157464e-01\n",
      "   6.95358679e-01 -1.84172322e+00  1.67911355e+00  8.07212275e-01\n",
      "  -1.61926728e+00  7.55097371e-01  1.23644953e+00  2.66026432e-01\n",
      "  -5.96493557e-01 -5.01932171e-01  1.23043256e-01 -5.33942964e-01\n",
      "   1.17718851e-01 -5.71756807e-01  1.10650352e+00  7.00600945e-01\n",
      "  -1.02951443e+00  5.54793112e-01 -4.59070139e-01  9.54813764e-01\n",
      "   1.37944425e+00 -1.25194684e+00  4.21578489e-01  1.27296709e+00\n",
      "   4.41128528e-01  3.27296944e-01  3.62542979e-01  1.15016973e+00\n",
      "  -2.44967496e-01  4.47723604e-01  1.92866430e-02 -1.27498533e+00\n",
      "   1.47634416e+00 -1.79192391e-01  8.13887892e-01 -3.38848265e-01\n",
      "  -7.00146900e-01  5.46657956e-01 -7.23560172e-01 -1.27666457e+00\n",
      "  -1.21887283e-02 -2.63472278e-01  5.47666850e-01 -2.31112662e+00\n",
      "  -8.89083118e-01  5.23576483e-02  2.66150666e+00  8.74214541e-01\n",
      "   8.92948520e-01 -7.15515005e-02  4.53972451e-03  1.44236953e+00\n",
      "  -3.56526755e-01 -9.10531028e-01  1.89560924e-02 -5.47163008e-01\n",
      "  -1.58810620e+00  7.67552623e-01  1.00069850e+00  8.40377224e-01\n",
      "  -1.31530384e+00  2.33484553e-01 -8.78407426e-02 -2.34392834e-02]\n",
      " [ 1.29293428e-01 -3.73922786e-01  9.91580459e-02 -1.09313466e+00\n",
      "  -3.43887662e-01 -5.54227412e-02  1.70369423e+00  9.54006886e-01\n",
      "  -4.52724528e-01 -9.78536713e-01  1.11999555e+00 -1.05179627e+00\n",
      "  -1.89021018e-01  1.30491817e+00 -6.03856253e-01 -1.61086228e-01\n",
      "   3.96761342e-01 -1.11542450e+00  8.24579882e-01  2.21253295e+00\n",
      "   1.29717508e+00 -8.11136155e-01  1.04149103e+00 -8.02291269e-03\n",
      "  -2.18194182e-01 -1.51094800e+00  1.16147757e+00  1.48556739e-01\n",
      "   5.68282058e-01 -1.88776456e+00 -3.38199757e-01 -6.23726054e-01\n",
      "  -5.26888647e-01  5.53499116e-01  5.63426404e-01  2.36592785e-01\n",
      "   1.15998961e+00 -1.47149858e-01  8.72696638e-01 -5.20161957e-01\n",
      "   1.09997826e+00  9.70478809e-01  1.35889271e+00  1.60748666e+00\n",
      "   1.12031934e+00 -1.10155542e+00 -4.14582120e-01 -6.95272257e-01\n",
      "  -9.94848822e-01  4.60878760e-01  4.44762904e-01  1.65353783e+00\n",
      "  -7.20408263e-01  4.92676888e-01  1.04013830e+00 -1.16430206e-01\n",
      "   1.36069855e-01  5.12717465e-01 -1.01293927e+00 -4.43769124e-01\n",
      "  -7.62855766e-02 -8.71566935e-01 -9.25302057e-01 -1.15240969e+00\n",
      "   1.55143503e+00  2.09260547e+00  1.31020023e+00 -5.75876040e-01\n",
      "  -8.19006305e-01 -3.14335924e+00 -7.89782317e-01 -1.54743865e+00\n",
      "   7.31613254e-01 -6.42994102e-01  3.38315998e-01 -7.04837893e-02\n",
      "  -5.43529013e-01  1.51440179e+00 -2.94415811e+00 -6.33379178e-01\n",
      "  -1.49296073e+00 -1.04975082e+00  9.29328833e-01 -1.51459303e+00\n",
      "   2.91361095e-02  3.27474637e-01  9.00161697e-01  1.42421845e+00\n",
      "  -3.23972272e-02  7.57617991e-01  1.14571271e+00 -1.22382091e-01\n",
      "   6.70624660e-01 -7.78256531e-01 -2.64380168e-01 -1.16166291e+00\n",
      "  -1.36627454e+00 -2.56819153e-01 -4.96758365e-01  1.62582540e-01]\n",
      " [ 2.86878364e-01  5.18842405e-02  1.13814954e-01 -5.26141588e-01\n",
      "   5.30097702e-01 -6.18909255e-01  1.51024821e+00  4.65504598e-01\n",
      "  -5.39277388e-01  4.42542836e-01 -1.27418499e+00  5.95716537e-01\n",
      "  -2.38518277e+00  2.07487785e+00 -7.09098885e-01  1.79087297e+00\n",
      "   7.26729398e-01  1.67251996e+00 -8.47312312e-01  1.04014876e+00\n",
      "   2.01192899e-01 -7.29507325e-02  1.14994457e+00  4.44612000e-01\n",
      "   9.35013877e-01 -5.93548452e-01  2.31183567e-02  2.90213921e-01\n",
      "  -1.19151639e+00 -3.46907904e-01 -7.96768762e-01  5.33473915e-01\n",
      "  -2.60939108e-01  7.95756875e-01  1.42067132e+00 -4.06502459e-01\n",
      "  -1.77467197e+00  8.08547127e-01  2.33990585e-01 -9.90850483e-01\n",
      "  -1.14398764e+00  1.09231929e+00  7.96066713e-02 -9.09919347e-02\n",
      "   1.52225151e+00 -1.44808535e+00 -6.19890672e-01 -1.51889176e+00\n",
      "  -1.21852199e+00 -4.73244857e-01 -8.08450524e-01 -2.12001905e-01\n",
      "  -7.15544855e-01  6.61923002e-01 -3.49553445e-01  1.25157689e-01\n",
      "   1.02709191e+00  6.30694319e-02 -2.03819977e+00  1.63140047e-01\n",
      "  -6.76593785e-01 -8.23268238e-01  1.20325440e+00  1.61257218e+00\n",
      "   1.41339356e+00 -1.20544698e+00  1.84039557e-01  8.49143532e-01\n",
      "   1.29240917e+00  9.34569502e-01 -1.41841589e+00 -1.64010068e+00\n",
      "   1.83823422e+00 -9.64219290e-01  1.47116297e-01 -1.24285517e+00\n",
      "  -1.24618242e-01  5.84969629e-01  2.18100846e-01  1.80841977e-01\n",
      "   4.42081510e-01  1.46081577e-01 -1.12250478e+00 -1.20596007e+00\n",
      "   1.48029184e+00 -8.82191013e-01 -1.01242711e+00 -3.85634907e-01\n",
      "   9.09564260e-01 -2.52470084e-02 -1.94353055e+00 -6.44653384e-01\n",
      "  -6.43159854e-01 -2.46931940e+00  3.91644705e-01  4.02601920e-01\n",
      "  -1.60584957e+00  4.57256097e-02  6.98716522e-01  6.02311539e-01]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Input to reshape is a tensor with 1024 values, but the requested shape has 3136\n\t [[node sequential_3/reshape_1/Reshape (defined at <ipython-input-30-4650c0834010>:2) ]] [Op:__inference_distributed_function_24412]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-04f1e9feffb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgen_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m               \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m               total_epochs=1)\n\u001b[0m\u001b[1;32m    476\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    604\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Input to reshape is a tensor with 1024 values, but the requested shape has 3136\n\t [[node sequential_3/reshape_1/Reshape (defined at <ipython-input-30-4650c0834010>:2) ]] [Op:__inference_distributed_function_24412]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "noise = np.random.normal(0, 1, size=[4, 100])\n",
    "print(noise)\n",
    "gen_imgs = G.predict(noise)\n",
    "for i in range(len(noise)):\n",
    "    plt.imshow((gen_imgs[i] + 1) / 2)\n",
    "    plt.show()\n",
    "    plt.imsave('img%02d.png' % i, gen_imgs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
